{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "import google.generativeai as genai\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_twitter_data(df):\n",
    "    df = df.copy()\n",
    "\n",
    "    # remove duplicates\n",
    "    df.drop_duplicates(subset=['tweets'], inplace=True)\n",
    "\n",
    "    # Drop empty tweets (after stripping)\n",
    "    df['tweets'] = df['tweets'].str.strip()\n",
    "    df = df[df['tweets'] != \"\"]\n",
    "\n",
    "    # Convert tweets and sentiment to lowercase and strip whitespace\n",
    "    df['tweets'] = df['tweets'].str.strip().str.lower()\n",
    "    df['sentiment'] = df['sentiment'].str.strip().str.lower()\n",
    "\n",
    "    # Drop irrelevant tweets\n",
    "    df = df[df['sentiment'] != 'irrelevant']\n",
    "\n",
    "    # Remove URLs and usernames from tweets\n",
    "    df['tweets'] = df['tweets'].str.replace(r'http\\S+|www\\S+|@\\S+', '', regex=True)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('twitter_training.csv')\n",
    "raw_df = pd.read_csv('twitter_training.csv')\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = preprocess_twitter_data(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(6, 3))\n",
    "df['sentiment'].value_counts().plot(kind='bar')\n",
    "plt.xlabel('Sentiment')\n",
    "plt.ylabel('Count')\n",
    "plt.title('Sentiment Distribution in Twitter Dataset')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "client = OpenAI(api_key=os.getenv('OPENAI_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment(tweet, entity, no_of_shots=0):\n",
    "    prompt_zero_shot = f\"\"\"Classify the sentiment of the following tweet as positive, negative, or neutral.\\nGive only the sentiment as single word output in lowercase. This is a strict requirement.\\nIf your output is mixed, output neutral.\\nTarget Sentence: \"{tweet}\"\\nSentiment:\"\"\"\n",
    "    \n",
    "    few_shot_examples = \"\"\"Use the following tweets as example for few shot learning. Each example is followed by a sentiment label.\"\"\"\n",
    "\n",
    "    isFewShot = no_of_shots > 0\n",
    "    if no_of_shots:\n",
    "        while no_of_shots:\n",
    "            positive_sample = df[(df['sentiment'] == 'positive') & (df['entity'] == entity)]['tweets'].sample(1).values[0]\n",
    "            while positive_sample == tweet:\n",
    "                positive_sample = df[(df['sentiment'] == 'positive') & (df['entity'] == entity)]['tweets'].sample(1).values[0]\n",
    "            negative_sample = df[(df['sentiment'] == 'negative') & (df['entity'] == entity)]['tweets'].sample(1).values[0]\n",
    "            while negative_sample == tweet:\n",
    "                negative_sample = df[(df['sentiment'] == 'negative') & (df['entity'] == entity)]['tweets'].sample(1).values[0]\n",
    "            neutral_sample = df[(df['sentiment'] == 'neutral') & (df['entity'] == entity)]['tweets'].sample(1).values[0]\n",
    "            while neutral_sample == tweet:\n",
    "                neutral_sample = df[(df['sentiment'] == 'neutral') & (df['entity'] == entity)]['tweets'].sample(1).values[0]\n",
    "            \n",
    "            few_shot_examples += \"\"\"\\nExample: {}\\nSentiment: {}\"\"\".format(positive_sample, 'positive')\n",
    "            few_shot_examples += \"\"\"\\nExample: {}\\nSentiment: {}\"\"\".format(negative_sample, 'negative')\n",
    "            few_shot_examples += \"\"\"\\nExample: {}\\nSentiment: {}\"\"\".format(neutral_sample, 'neutral')\n",
    "            no_of_shots -= 1\n",
    "    \n",
    "    prompt_few_shot = few_shot_examples + \"\\n\"+prompt_zero_shot\n",
    "    response = client.chat.completions.create(\n",
    "        model=\"gpt-4o\",\n",
    "        messages=[{\"role\": \"system\", \"content\": \"You are a sentiment analysis expert.\"},\n",
    "                  {\"role\": \"user\", \"content\": prompt_few_shot if isFewShot else prompt_zero_shot}],\n",
    "        temperature=0\n",
    "    )\n",
    "\n",
    "    sentiment = response.choices[0].message.content.strip()\n",
    "\n",
    "    isPositive =  'positive' in sentiment.lower()\n",
    "    isNegative = \"negative\" in sentiment.lower()\n",
    "    isNeutral = \"neutral\" in sentiment.lower()\n",
    "\n",
    "    if not isPositive and not isNegative and not isNeutral:\n",
    "        if 'mixed' in sentiment:\n",
    "            sentiment = 'neutral'\n",
    "        else:\n",
    "            if \":\" in sentiment:\n",
    "                sentiment = sentiment.split(\":\")[1].strip()\n",
    "            if \".\" in sentiment:\n",
    "                sentiment = sentiment.split(\".\")[0].strip()\n",
    "            if not sentiment:\n",
    "                sentiment = 'invalid'\n",
    "    # if more than one word in sentiment or sentiment is not in ['positive', 'negative', 'neutral'], mark as invalid\n",
    "    if (isPositive and isNegative) or (isPositive and isNeutral) or (isNegative and isNeutral):\n",
    "        sentiment = 'invalid'\n",
    "    return sentiment.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_sample = pd.read_csv('twitter_training.csv') # replace this actual batched file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero shot gpt\n",
    "zero_shot_predictions = [get_sentiment(tweet, entity) for tweet, entity in zip(df_sample['tweets'], df_sample['entity'])]\n",
    "y_true = df_sample['sentiment'].str.lower()\n",
    "zero_shot_accuracy = accuracy_score(y_true, zero_shot_predictions)\n",
    "print(\"\\nZero-Shot Classification Report:\\n\", classification_report(y_true, zero_shot_predictions, digits=4))\n",
    "print(confusion_matrix(y_true, zero_shot_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 shot gpt\n",
    "one_shot_predictions = [get_sentiment(tweet, entity, no_of_shots=1) for tweet, entity in zip(df_sample['tweets'], df_sample['entity'])]\n",
    "one_shot_accuracy = accuracy_score(y_true, one_shot_predictions)\n",
    "print(\"One-Shot Accuracy:\", one_shot_accuracy)\n",
    "print(\"\\nOne-Shot Classification Report:\\n\", classification_report(y_true, one_shot_predictions, digits=4))\n",
    "print(confusion_matrix(y_true, one_shot_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 shot gpt\n",
    "three_shot_predictions = [get_sentiment(tweet, entity, no_of_shots=3) for tweet, entity in zip(df_sample['tweets'], df_sample['entity'])]\n",
    "three_shot_accuracy = accuracy_score(y_true, three_shot_predictions)\n",
    "print(\"Few-Shot Accuracy:\", three_shot_accuracy)\n",
    "print(\"\\nThree-Shot Classification Report:\\n\", classification_report(y_true, three_shot_predictions, digits=4))\n",
    "print(confusion_matrix(y_true, three_shot_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "genai.configure(api_key=os.getenv('GEMINI_API_KEY'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentiment_gemini(tweet, entity, no_of_shots=0):\n",
    "    prompt_zero_shot = f\"\"\"Classify the sentiment of the following tweet as positive, negative, or neutral.\n",
    "    Give only the sentiment as a single lowercase word â€” \"positive\", \"negative\", or \"neutral\". This is a strict requirement.\n",
    "    If the sentiment is unclear or mixed, output \"neutral\".\n",
    "    Target Sentence: \"{tweet}\"\n",
    "    Sentiment:\"\"\"\n",
    "\n",
    "    few_shot_examples = \"Use the following tweets as examples for few-shot learning. Each example is followed by a sentiment label:\\n\"\n",
    "\n",
    "    isFewShot = no_of_shots > 0\n",
    "    if isFewShot:\n",
    "        for _ in range(no_of_shots):\n",
    "            positive_sample = df[(df['sentiment'] == 'positive') & (df['entity'] == entity)]['tweets'].sample(1).values[0]\n",
    "            while positive_sample == tweet:\n",
    "                positive_sample = df[(df['sentiment'] == 'positive') & (df['entity'] == entity)]['tweets'].sample(1).values[0]\n",
    "\n",
    "            negative_sample = df[(df['sentiment'] == 'negative') & (df['entity'] == entity)]['tweets'].sample(1).values[0]\n",
    "            while negative_sample == tweet:\n",
    "                negative_sample = df[(df['sentiment'] == 'negative') & (df['entity'] == entity)]['tweets'].sample(1).values[0]\n",
    "\n",
    "            neutral_sample = df[(df['sentiment'] == 'neutral') & (df['entity'] == entity)]['tweets'].sample(1).values[0]\n",
    "            while neutral_sample == tweet:\n",
    "                neutral_sample = df[(df['sentiment'] == 'neutral') & (df['entity'] == entity)]['tweets'].sample(1).values[0]\n",
    "\n",
    "            few_shot_examples += f\"\\nExample: {positive_sample}\\nSentiment: positive\"\n",
    "            few_shot_examples += f\"\\nExample: {negative_sample}\\nSentiment: negative\"\n",
    "            few_shot_examples += f\"\\nExample: {neutral_sample}\\nSentiment: neutral\"\n",
    "\n",
    "    prompt_few_shot = few_shot_examples + \"\\n\"+prompt_zero_shot\n",
    "    print(\"prompting\", prompt_few_shot if isFewShot else prompt_zero_shot)\n",
    "    model = genai.GenerativeModel(model_name=\"models/gemini-1.5-pro\")\n",
    "    response = model.generate_content(prompt_few_shot if isFewShot else prompt_zero_shot)\n",
    "    print(\"received response\")\n",
    "    sentiment = response.text.strip().lower()  \n",
    "\n",
    "    isPositive = \"positive\" in sentiment\n",
    "    isNegative = \"negative\" in sentiment\n",
    "    isNeutral = \"neutral\" in sentiment\n",
    "\n",
    "    if not isPositive and not isNegative and not isNeutral:\n",
    "        if 'mixed' in sentiment:\n",
    "            sentiment = 'neutral'\n",
    "        else:\n",
    "            if \":\" in sentiment:\n",
    "                sentiment = sentiment.split(\":\")[1].strip()\n",
    "            if \".\" in sentiment:\n",
    "                sentiment = sentiment.split(\".\")[0].strip()\n",
    "            if not sentiment:\n",
    "                sentiment = 'invalid'\n",
    "\n",
    "    if (isPositive and isNegative) or (isPositive and isNeutral) or (isNegative and isNeutral):\n",
    "        sentiment = 'invalid'\n",
    "    print(tweet, sentiment)\n",
    "    return sentiment\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# zero shot gemini\n",
    "zero_shot_predictions = [get_sentiment_gemini(tweet, entity) for tweet, entity in zip(df_sample['tweets'], df_sample['entity'])]\n",
    "y_true = df_sample['sentiment'].str.lower()\n",
    "zero_shot_accuracy = accuracy_score(y_true, zero_shot_predictions)\n",
    "print(confusion_matrix(y_true, zero_shot_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1 shot gemini\n",
    "one_shot_predictions = [get_sentiment_gemini(tweet, entity, no_of_shots=1) for tweet, entity in zip(df_sample['tweets'], df_sample['entity'])]\n",
    "one_shot_accuracy = accuracy_score(y_true, one_shot_predictions)\n",
    "print(\"One-Shot Accuracy:\", one_shot_accuracy)\n",
    "print(\"\\nOne-Shot Classification Report:\\n\", classification_report(y_true, one_shot_predictions))\n",
    "print(confusion_matrix(y_true, one_shot_predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3 shot gemini\n",
    "three_shot_predictions = [get_sentiment_gemini(tweet, entity, no_of_shots=3) for tweet, entity in zip(df_sample['tweets'], df_sample['entity'])]\n",
    "three_shot_accuracy = accuracy_score(y_true, three_shot_predictions)\n",
    "print(\"Few-Shot Accuracy:\", three_shot_accuracy)\n",
    "print(\"\\nThree-Shot Classification Report:\\n\", classification_report(y_true, three_shot_predictions, digits=4))\n",
    "print(confusion_matrix(y_true, three_shot_predictions))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
